{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxpuzdFyvXXC",
        "outputId": "7cc0364a-17d8-4b38-d39e-da53fd2bdd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rHit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rHit:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Connecting to security.ub\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.39)] [Waiting for headers] [Wai\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "\r                                                                               \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:7 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers]\r                                              \rGet:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:10 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,499 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [76.4 kB]\n",
            "Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,182 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,034 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,331 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,111 kB]\n",
            "Fetched 9,591 kB in 2s (4,813 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOsLh5h4vpkz",
        "outputId": "5a17602d-e511-4a89-bbfe-3a80eefddde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-w30jq8x0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-w30jq8x0\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=627a55e033baf8974250bb44fb95472acf3739ecdfd10f76965280b86fdcec65\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mfoo37me/wheels/db/c1/1f/a2bb07bbb4a1ce3c43921252aeafaa6205f08637e292496f04\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAzYGDKIwE-E",
        "outputId": "f67ff625-9a30-44a8-bd65-0691a7ba0fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "int main() {\n",
        "    std::cout << \"Welcome To OxyWorld\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDfigrrwwniV",
        "outputId": "1243d89a-0b96-49a7-f21e-428b79953967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome To OxyWorld\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZJg1ANDrw_TF",
        "outputId": "c33a725d-0b91-4ca1-cbff-2cc6d91736a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib"
      ],
      "metadata": {
        "id": "J2vS2mnnxzLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeZf0KpHyTP7",
        "outputId": "4614e27a-98ba-45da-e96b-8c56bbea9517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 6813887808366020036\n",
              " xla_global_id: -1,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14343274496\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 1076172089791909364\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC91eUQzyiOs",
        "outputId": "cb813b08-bc62-4d21-9fcd-fd155612dac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x86_64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/lsb-release"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr4vrA97yq8J",
        "outputId": "d349c83f-7e43-4dfa-cbb3-8cd2dddece78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=20.04\n",
            "DISTRIB_CODENAME=focal\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 20.04.5 LTS\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofYiVgOJy0l2",
        "outputId": "62e625a6-cc4c-4981-d58a-89fc8a05233a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux e8276bc1ea9b 5.10.147+ #1 SMP Sat Dec 10 16:00:40 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPp1n7HGy99B",
        "outputId": "0d65d70c-b98d-4f6f-949d-32317ba478fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 21 17:11:25 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    28W /  70W |    373MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ro_qX8zJi1",
        "outputId": "96bca283-a810-4021-db78-16bc7a3e6377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9eShPa-zRDr",
        "outputId": "d4d1c82f-1bd0-4b57-8090-2ffdf734485b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/meminfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws3wKt65zeGp",
        "outputId": "74555873-e6d4-4e78-f43f-bf53d4179137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MemTotal:       13297192 kB\n",
            "MemFree:         6837388 kB\n",
            "MemAvailable:   11009716 kB\n",
            "Buffers:          344056 kB\n",
            "Cached:          3998272 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           789784 kB\n",
            "Inactive:        5268648 kB\n",
            "Active(anon):       2156 kB\n",
            "Inactive(anon):  1702832 kB\n",
            "Active(file):     787628 kB\n",
            "Inactive(file):  3565816 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               356 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       1716112 kB\n",
            "Mapped:           782888 kB\n",
            "Shmem:             13764 kB\n",
            "KReclaimable:     120668 kB\n",
            "Slab:             164040 kB\n",
            "SReclaimable:     120668 kB\n",
            "SUnreclaim:        43372 kB\n",
            "KernelStack:        5616 kB\n",
            "PageTables:        21860 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648596 kB\n",
            "Committed_AS:    4467936 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       78064 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1352 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      224056 kB\n",
            "DirectMap2M:     5015552 kB\n",
            "DirectMap1G:    10485760 kB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#define N  64\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        "__global__ void matrixMulGPU( int * a, int * b, int * c )\n",
        "{\n",
        "  /*\n",
        "   * Build out this kernel.\n",
        "   */\n",
        "    int row = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    int col = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int val = 0;\n",
        "    if (row < N && col < N) {\n",
        "      for (int i = 0; i < N; ++i) {\n",
        "         val += a[row * N + i] * b[i * N + col];\n",
        "       }\n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}\n",
        "/*\n",
        " * This CPU function already works, and will run to create a solution matrix\n",
        " * against which to verify your work building out the matrixMulGPU kernel.\n",
        " */\n",
        "void matrixMulCPU( int * a, int * b, int * c )\n",
        "{\n",
        "  int val = 0;\n",
        "for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      val = 0;\n",
        "      for ( int k = 0; k < N; ++k )\n",
        "        val += a[row * N + k] * b[k * N + col];\n",
        "      c[row * N + col] = val;\n",
        "    }\n",
        "}\n",
        "int main()\n",
        "{\n",
        "  int *a, *b, *c_cpu, *c_gpu; // Allocate a solution matrix for both the CPU and the GPU operations\n",
        "int size = N * N * sizeof (int); // Number of bytes of an N x N matrix\n",
        "// Allocate memory\n",
        "  cudaMallocManaged (&a, size);\n",
        "  cudaMallocManaged (&b, size);\n",
        "  cudaMallocManaged (&c_cpu, size);\n",
        "  cudaMallocManaged (&c_gpu, size);\n",
        "// Initialize memory; create 2D matrices\n",
        "  for( int row = 0; row < N; ++row )\n",
        "    for( int col = 0; col < N; ++col )\n",
        "    {\n",
        "      a[row*N + col] = row;\n",
        "      b[row*N + col] = col+2;\n",
        "      c_cpu[row*N + col] = 0;\n",
        "      c_gpu[row*N + col] = 0;\n",
        "    }\n",
        "/*\n",
        "   * Assign `threads_per_block` and `number_of_blocks` 2D values\n",
        "   * that can be used in matrixMulGPU above.\n",
        "   */\n",
        "dim3 threads_per_block(32, 32, 1);\n",
        "  dim3 number_of_blocks(N / threads_per_block.x + 1, N / threads_per_block.y + 1, 1);\n",
        "matrixMulGPU <<< number_of_blocks, threads_per_block >>> ( a, b, c_gpu );\n",
        "checkCudaErr(cudaDeviceSynchronize(), \"Syncronization\");\n",
        "checkCudaErr(cudaGetLastError(), \"GPU\");\n",
        "// Call the CPU version to check our work\n",
        "  matrixMulCPU( a, b, c_cpu );\n",
        "// Compare the two answers to make sure they are equal\n",
        "  bool error = false;\n",
        "  for( int row = 0; row < N && !error; ++row )\n",
        "    for( int col = 0; col < N && !error; ++col )\n",
        "      if (c_cpu[row * N + col] != c_gpu[row * N + col])\n",
        "      {\n",
        "        printf(\"FOUND ERROR at c[%d][%d]\\n\", row, col);\n",
        "        error = true;\n",
        "        break;\n",
        "      }\n",
        "if (!error)\n",
        "    printf(\"Success!\\n\");\n",
        "// Free all our allocated memory\n",
        "  cudaFree(a); cudaFree(b);\n",
        "  cudaFree( c_cpu ); cudaFree( c_gpu );\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_ybVuu2gkr",
        "outputId": "81d94584-128d-4890-a3bf-ebb95a46c318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "if(err!=cudaSuccess) {\n",
        "  printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        " }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;}"
      ],
      "metadata": {
        "id": "KuVhaNE2234-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48582ec5-05b9-4527-f574-732f91796c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Cell magic `%%cu` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EmUqxLxkLOGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}